{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dfe0ba-e5d6-47a9-915f-886098cbffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n",
      "DataFrame after dropping 'Context-Domain':\n",
      "            Consumer             Producer Integration Type\n",
      "0     Payroll System    Research Database    REST-JSON-RPC\n",
      "1     Finance System  Analytics Dashboard             SFTP\n",
      "2     Finance System            HR System              ETL\n",
      "3  IT Support System  Analytics Dashboard             SFTP\n",
      "4     Finance System     Inventory System              ETL\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load CSV File\n",
    "import pandas as pd\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Load a CSV file and return a DataFrame.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(\"CSV loaded successfully!\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test loading the CSV\n",
    "csv_file = \"sample_integration_data.csv\"  # Replace with your actual CSV path\n",
    "data = load_csv(csv_file)\n",
    "\n",
    "# Drop the 'Context-Domain' column\n",
    "data = data.drop(columns=['Context-Domain'], errors='ignore')\n",
    "\n",
    "# Display the first few rows to confirm the column is dropped\n",
    "print(\"DataFrame after dropping 'Context-Domain':\")\n",
    "\n",
    "# Display the first few rows of the data\n",
    "if data is not None:\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c284218b-ea36-438f-87ed-a67d7e727b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database populated with 100 points!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, PointStruct\n",
    "\n",
    "# Initialize SentenceTransformer model\n",
    "vectorizer = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Set up Qdrant\n",
    "def setup_vector_db(data):\n",
    "    \"\"\"\n",
    "    Create and populate an in-memory Qdrant vector database with graph data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Qdrant client (in-memory)\n",
    "        client = QdrantClient(\":memory:\")\n",
    "        \n",
    "        # Define vector collection schema\n",
    "        collection_name = \"systems\"\n",
    "        if client.get_collections().collections:\n",
    "            client.delete_collection(collection_name)\n",
    "        \n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=384, distance=\"Cosine\")\n",
    "        )\n",
    "\n",
    "        # Populate the database\n",
    "        points = []\n",
    "        for idx, row in data.iterrows():\n",
    "            # Create a descriptive text for the relationship\n",
    "            interaction_text = f\"{row['Consumer']} interacts with {row['Producer']} via {row['Integration Type']}\"\n",
    "            \n",
    "            # Encode text into a vector\n",
    "            embedding = vectorizer.encode(interaction_text).tolist()\n",
    "            \n",
    "            # Add point with metadata\n",
    "            points.append(\n",
    "                PointStruct(\n",
    "                    id=idx,  # Unique ID\n",
    "                    vector=embedding,\n",
    "                    payload={\n",
    "                        \"consumer\": row['Consumer'],\n",
    "                        \"producer\": row['Producer'],\n",
    "                        \"integration\": row['Integration Type']\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Upsert points into Qdrant\n",
    "        client.upsert(collection_name=collection_name, points=points)\n",
    "        print(f\"Vector database populated with {len(points)} points!\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up vector database: {e}\")\n",
    "        return None\n",
    "\n",
    "# Set up the vector database\n",
    "vector_db_client = setup_vector_db(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec262398-2d36-497c-a0a9-226058739846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query 'HR' as a consumer:\n",
      "{'consumer': 'HR System', 'producer': 'Admissions Portal', 'integration': 'REST-API'}\n",
      "{'consumer': 'HR System', 'producer': 'Admissions Portal', 'integration': 'REST-API'}\n",
      "{'consumer': 'HR System', 'producer': 'Finance System', 'integration': 'REST-API'}\n",
      "{'consumer': 'HR System', 'producer': 'Finance System', 'integration': 'REST-API'}\n",
      "{'consumer': 'HR System', 'producer': 'Payroll System', 'integration': 'SFTP'}\n"
     ]
    }
   ],
   "source": [
    "def query_vector_db(client, query, role=\"consumer\", top_k=5):\n",
    "    \"\"\"\n",
    "    Query the Qdrant vector database for relevant interactions.\n",
    "    \n",
    "    Args:\n",
    "        client (QdrantClient): Qdrant client instance.\n",
    "        query (str): Search query (e.g., \"HR system\").\n",
    "        role (str): Specify whether to prioritize as 'consumer' or 'producer'.\n",
    "        top_k (int): Number of top results to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "        list: Relevant interactions from the database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Encode the query into a vector\n",
    "        query_embedding = vectorizer.encode(query).tolist()\n",
    "        \n",
    "        # Perform a similarity search in Qdrant\n",
    "        results = client.search(\n",
    "            collection_name=\"systems\",\n",
    "            query_vector=query_embedding,\n",
    "            limit=top_k\n",
    "        )\n",
    "        \n",
    "        # Filter results based on the role (consumer/producer)\n",
    "        filtered_results = []\n",
    "        for result in results:\n",
    "            if role == \"consumer\" and query in result.payload[\"consumer\"]:\n",
    "                filtered_results.append(result.payload)\n",
    "            elif role == \"producer\" and query in result.payload[\"producer\"]:\n",
    "                filtered_results.append(result.payload)\n",
    "        \n",
    "        return filtered_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying vector database: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example Query\n",
    "query = \"HR\"\n",
    "role = \"consumer\"  # Can be \"consumer\" or \"producer\"\n",
    "retrieved_context = query_vector_db(vector_db_client, query, role=role, top_k=5)\n",
    "\n",
    "# Display Results\n",
    "print(f\"Results for query '{query}' as a {role}:\")\n",
    "for context in retrieved_context:\n",
    "    print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1fae57-bea3-47cd-bd59-423d69ccf007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entity: a, Role: producer\n"
     ]
    }
   ],
   "source": [
    "def interpret_query(query):\n",
    "    \"\"\"\n",
    "    Interpret a natural language query to extract the entity and role.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User's query.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Extracted entity and role (e.g., ('HR', 'consumer')).\n",
    "    \"\"\"\n",
    "    query = query.lower()  # Normalize to lowercase for consistent matching\n",
    "\n",
    "    # Check if 'consumer', 'producer', or 'integration' is mentioned\n",
    "    if \"consumer\" in query:\n",
    "        role = \"consumer\"\n",
    "        entity = query.split(\"consumer\")[0].strip().split()[-1]  # Extract entity before 'consumer'\n",
    "    elif \"producer\" in query:\n",
    "        role = \"producer\"\n",
    "        entity = query.split(\"producer\")[0].strip().split()[-1]  # Extract entity before 'producer'\n",
    "    elif \"integration\" in query:\n",
    "        role = None  # No direct consumer/producer context\n",
    "        entity = query.split(\"integration\")[0].strip().split()[-1]  # Extract entity before 'integration'\n",
    "    else:\n",
    "        # Default case: assume the last word as the entity and 'consumer' as the role\n",
    "        role = \"consumer\"\n",
    "        entity = query.strip().split()[-1]\n",
    "\n",
    "    return entity, role\n",
    "\n",
    "# Example query\n",
    "test_query = \"What are the systems HR is a producer for?\"\n",
    "entity, role = interpret_query(test_query)\n",
    "print(f\"Extracted Entity: {entity}, Role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c227ece-2a9f-4fb5-8601-5dbf8bb938b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query 'What are the systems HR is a producer for?':\n",
      "{'consumer': 'Analytics Dashboard', 'producer': 'Admissions Portal', 'integration': 'Event-Queue'}\n",
      "{'consumer': 'Inventory System', 'producer': 'Research Database', 'integration': 'REST-API'}\n"
     ]
    }
   ],
   "source": [
    "# Query the vector database with a natural language input\n",
    "test_query = \"What are the systems HR is a producer for?\"\n",
    "entity, role = interpret_query(test_query)\n",
    "\n",
    "# Perform the query\n",
    "retrieved_context = query_vector_db(vector_db_client, entity, role=role, top_k=5)\n",
    "\n",
    "# Display results\n",
    "print(f\"Results for query '{test_query}':\")\n",
    "for context in retrieved_context:\n",
    "    print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f788b17-8f90-4f53-be04-63a26d585781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(query, context):\n",
    "    \"\"\"\n",
    "    Create a prompt for AWS Bedrock to ensure a structured JSON response.\n",
    "\n",
    "    Args:\n",
    "        query (str): User's query.\n",
    "        context (list): List of interactions retrieved from Qdrant.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted prompt.\n",
    "    \"\"\"\n",
    "    formatted_context = \"\\n\".join([\n",
    "        f\"Consumer: {item['consumer']}, Producer: {item['producer']}, Integration: {item['integration']}\"\n",
    "        for item in context\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a JSON generation assistant. Based on the query and context provided, generate a JSON object with the following structure:\n",
    "{{\n",
    "    \"nodes\": [\n",
    "        {{\"id\": \"System A\"}},\n",
    "        ...\n",
    "    ],\n",
    "    \"edges\": [\n",
    "        {{\"consumer\": \"System A\", \"producer\": \"System B\", \"integration\": \"Type\"}},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "Do not include any text outside of the JSON object.\n",
    "\n",
    "Query: {query}\n",
    "Context:\n",
    "{formatted_context}\n",
    "</SYS> </INST>\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e6470-4dda-4b87-8352-27ebb219c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock Runtime client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Load environment variables\n",
    "BEDROCK_INFERENCE_PROFILE_ARN = os.getenv(\"BEDROCK_INFERENCE_PROFILE_ARN\")\n",
    "AWS_AGENT_ARN = os.getenv(\"AWS_AGENT_ARN\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")  # Default to us-east-1\n",
    "\n",
    "# Validate environment variables\n",
    "assert BEDROCK_INFERENCE_PROFILE_ARN, \"BEDROCK_INFERENCE_PROFILE_ARN is not set\"\n",
    "assert AWS_AGENT_ARN, \"AWS_AGENT_ARN is not set\"\n",
    "\n",
    "# Initialize Bedrock Runtime client\n",
    "bedrock_client_runtime = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=AWS_REGION,\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    ")\n",
    "\n",
    "print(\"Bedrock Runtime client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa3b69-90cb-4e71-bb46-c71f75cb048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize Bedrock Runtime client\n",
    "bedrock = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",  # Replace with your AWS region\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    ")\n",
    "\n",
    "def invoke_bedrock_agent(query, context):\n",
    "    \"\"\"\n",
    "    Invoke AWS Bedrock with the query and context.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User's query.\n",
    "        context (list): Retrieved context from Qdrant.\n",
    "\n",
    "    Returns:\n",
    "        dict: JSON response from Bedrock.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the prompt\n",
    "        prompt = create_prompt(query, context)\n",
    "\n",
    "        # Invoke Bedrock Runtime\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=\"your-model-arn-or-id\",  # Replace with your model ARN or ID\n",
    "            body=json.dumps({\"inputText\": prompt}),\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\"\n",
    "        )\n",
    "\n",
    "        # Parse and return the response\n",
    "        response_body = json.loads(response['body'])\n",
    "        print(\"Bedrock Response:\", json.dumps(response_body, indent=2))\n",
    "        return response_body\n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking Bedrock: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "query = \"What systems does HR interact with?\"\n",
    "bedrock_response = invoke_bedrock_agent(query, retrieved_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
