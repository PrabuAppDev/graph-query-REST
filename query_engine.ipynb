{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36bcd531-ff28-4249-a8fe-30d933e6ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer</th>\n",
       "      <th>Producer</th>\n",
       "      <th>Integration Type</th>\n",
       "      <th>Context-Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Payroll System</td>\n",
       "      <td>Research Database</td>\n",
       "      <td>REST-JSON-RPC</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finance System</td>\n",
       "      <td>Analytics Dashboard</td>\n",
       "      <td>SFTP</td>\n",
       "      <td>Alumni Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finance System</td>\n",
       "      <td>HR System</td>\n",
       "      <td>ETL</td>\n",
       "      <td>Admissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT Support System</td>\n",
       "      <td>Analytics Dashboard</td>\n",
       "      <td>SFTP</td>\n",
       "      <td>Student Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finance System</td>\n",
       "      <td>Inventory System</td>\n",
       "      <td>ETL</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Consumer             Producer Integration Type    Context-Domain\n",
       "0     Payroll System    Research Database    REST-JSON-RPC          Research\n",
       "1     Finance System  Analytics Dashboard             SFTP  Alumni Relations\n",
       "2     Finance System            HR System              ETL        Admissions\n",
       "3  IT Support System  Analytics Dashboard             SFTP  Student Services\n",
       "4     Finance System     Inventory System              ETL           Finance"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load and inspect the CSV\n",
    "def load_csv(file_path):\n",
    "    \"\"\"\n",
    "    Load a CSV file and return a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(\"CSV loaded successfully!\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'sample_integration_data.csv'\n",
    "\n",
    "# Load the CSV\n",
    "integration_data = load_csv(file_path)\n",
    "\n",
    "# Display the first few rows for inspection\n",
    "if integration_data is not None:\n",
    "    print(\"Sample Data:\")\n",
    "    display(integration_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb55d3e-75cd-4ce2-a9ba-2e1af4b1600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -v qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34914b72-c4d8-433f-9c95-fe514010f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13cce9254d54dc88e671f6456bb2dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169969ba4bd5404ab3cad29000283090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12078033eb0d41f385f83d54fdd8808e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fff4b5e1d26443f8cbde98264a0a5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412d8eefaf1d491f803083f7ce4ef55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba1a5b445b843b2a9811b6836692a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aee454125d54a4b80efa623fd1950b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53179e57eafe4b9bb2fa17c1db9e37b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311832b4113b4e169e3d2867bbe046c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d11d9fb7dc040458b3dd2082bb94e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1e220a78b8422cb693d75769d9fffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9y/6280fw495y76ng470pndcvt40000gn/T/ipykernel_81975/2603742439.py:21: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database populated with 100 points!\n",
      "Vector database setup successful!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import qdrant_client\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "# Initialize vectorizer (e.g., SentenceTransformer)\n",
    "vectorizer = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Function to prepare and store data in the vector database\n",
    "def setup_vector_db(graph):\n",
    "    \"\"\"\n",
    "    Create and populate an in-memory vector database with graph data.\n",
    "\n",
    "    Args:\n",
    "        graph (dict): Graph representation with `nodes` and `edges`.\n",
    "\n",
    "    Returns:\n",
    "        QdrantClient: In-memory Qdrant client with indexed data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = qdrant_client.QdrantClient(\":memory:\")  # In-memory instance\n",
    "        client.recreate_collection(\n",
    "            collection_name=\"systems\",\n",
    "            vectors_config=qdrant_client.http.models.VectorParams(\n",
    "                size=384, distance=\"Cosine\"  # Embedding size from the model\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add graph data to the collection\n",
    "        points = []\n",
    "        for edge in graph[\"edges\"]:\n",
    "            text = f\"{edge['source']} interacts with {edge['target']} via {edge['integration']}\"\n",
    "            embedding = vectorizer.encode(text).tolist()\n",
    "            points.append(\n",
    "                PointStruct(\n",
    "                    id=len(points), vector=embedding,\n",
    "                    payload={\"source\": edge[\"source\"], \"target\": edge[\"target\"],\n",
    "                             \"integration\": edge[\"integration\"], \"context\": edge[\"context\"]}\n",
    "                )\n",
    "            )\n",
    "\n",
    "        client.upsert(collection_name=\"systems\", points=points)\n",
    "        print(f\"Vector database populated with {len(points)} points!\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up vector database: {e}\")\n",
    "        return None\n",
    "\n",
    "# Set up the vector database\n",
    "vector_db_client = setup_vector_db(graph)\n",
    "\n",
    "# Confirm successful setup\n",
    "if vector_db_client:\n",
    "    print(\"Vector database setup successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b92105d-5c7d-4bfa-9b83-8f4aa9e85609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 context items for query: 'What are the systems that interact with Finance System?'\n",
      "Context retrieval successful!\n",
      "Retrieved Context: [{'source': 'Finance System', 'target': 'Finance System', 'integration': 'REST-JSON-RPC', 'context': 'Reporting'}, {'source': 'Finance System', 'target': 'Inventory System', 'integration': 'ETL', 'context': 'Finance'}, {'source': 'HR System', 'target': 'Finance System', 'integration': 'CDC-Stream', 'context': 'Alumni Relations'}, {'source': 'Finance System', 'target': 'Inventory System', 'integration': 'SFTP', 'context': 'Student Services'}, {'source': 'Finance System', 'target': 'CRM System', 'integration': 'ETL', 'context': 'Finance'}]\n"
     ]
    }
   ],
   "source": [
    "def retrieve_context_from_vector_db(client, query, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context for the query from the vector database.\n",
    "\n",
    "    Args:\n",
    "        client (QdrantClient): Qdrant client instance.\n",
    "        query (str): The natural language query.\n",
    "        top_k (int): Number of top results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: Retrieved context from the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_embedding = vectorizer.encode(query).tolist()\n",
    "        results = client.search(\n",
    "            collection_name=\"systems\",\n",
    "            query_vector=query_embedding,\n",
    "            limit=top_k\n",
    "        )\n",
    "        context = [\n",
    "            result.payload for result in results\n",
    "        ]\n",
    "        print(f\"Retrieved {len(context)} context items for query: '{query}'\")\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying vector database: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example query\n",
    "example_query = \"What are the systems that interact with Finance System?\"\n",
    "retrieved_context = retrieve_context_from_vector_db(vector_db_client, example_query)\n",
    "\n",
    "# Confirm successful retrieval\n",
    "if retrieved_context:\n",
    "    print(\"Context retrieval successful!\")\n",
    "    print(\"Retrieved Context:\", retrieved_context)\n",
    "else:\n",
    "    print(\"No context retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccced211-d0b5-4743-8c0c-fdf145b502e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'EleutherAI/gpt-neo-125M' loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Function to load the LLM\n",
    "def load_llm(model_name=\"EleutherAI/gpt-neo-125M\"):\n",
    "    \"\"\"\n",
    "    Load a local LLM for processing queries.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the Hugging Face model to load.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer, model: The tokenizer and model for the LLM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        print(f\"Model '{model_name}' loaded successfully!\")\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer, model = load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "257bb307-b7e2-4d7e-9afa-11485efab626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context: [{'source': 'Finance System', 'target': 'Inventory System', 'integration': 'ETL', 'context': 'Finance'}, {'source': 'Finance System', 'target': 'CRM System', 'integration': 'REST-API', 'context': 'Marketing'}, {'source': 'HR System', 'target': 'Finance System', 'integration': 'CDC-Stream', 'context': 'Employee Data'}]\n",
      "Testing JSON Generation with Few-Shot Prompt...\n",
      "Raw OpenAI Response: {\n",
      "  \"query\": \"What are the systems that interact with Finance System?\",\n",
      "  \"nodes\": [\n",
      "    {\"id\": \"Finance System\"},\n",
      "    {\"id\": \"Inventory System\"},\n",
      "    {\"id\": \"CRM System\"},\n",
      "    {\"id\": \"HR System\"}\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\"source\": \"Finance System\", \"target\": \"Inventory System\", \"integration\": \"ETL\", \"context\": \"Finance\"},\n",
      "    {\"source\": \"Finance System\", \"target\": \"CRM System\", \"integration\": \"REST-API\", \"context\": \"Marketing\"},\n",
      "    {\"source\": \"HR System\", \"target\": \"Finance System\", \"integration\": \"CDC-Stream\", \"context\": \"Employee Data\"}\n",
      "  ]\n",
      "}\n",
      "Generated JSON Response: {\n",
      "  \"query\": \"What are the systems that interact with Finance System?\",\n",
      "  \"nodes\": [\n",
      "    {\"id\": \"Finance System\"},\n",
      "    {\"id\": \"Inventory System\"},\n",
      "    {\"id\": \"CRM System\"},\n",
      "    {\"id\": \"HR System\"}\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\"source\": \"Finance System\", \"target\": \"Inventory System\", \"integration\": \"ETL\", \"context\": \"Finance\"},\n",
      "    {\"source\": \"Finance System\", \"target\": \"CRM System\", \"integration\": \"REST-API\", \"context\": \"Marketing\"},\n",
      "    {\"source\": \"HR System\", \"target\": \"Finance System\", \"integration\": \"CDC-Stream\", \"context\": \"Employee Data\"}\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client with API key from environment variable\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_response(messages, model=\"gpt-4o-mini\", max_tokens=500, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Generate a response using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        messages (list): List of messages for the conversation.\n",
    "        model (str): Model to use for generation (e.g., \"gpt-4o-mini\").\n",
    "        max_tokens (int): Maximum tokens for the output.\n",
    "        temperature (float): Sampling temperature for randomness.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated response content.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def generate_json_with_openai_few_shot(context, query):\n",
    "    \"\"\"\n",
    "    Generate a strict JSON response using the OpenAI API with few-shot examples.\n",
    "\n",
    "    Args:\n",
    "        context (list): Context retrieved from the vector database.\n",
    "        query (str): User query.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON response as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Format context for the API\n",
    "        formatted_context = \"\\n\".join([\n",
    "            f\"Source: {item['source']}, Target: {item['target']}, Integration: {item['integration']}, Context: {item['context']}\"\n",
    "            for item in context\n",
    "        ])\n",
    "\n",
    "        # Few-shot examples to guide the model\n",
    "        few_shot_examples = \"\"\"\n",
    "Example 1:\n",
    "Context:\n",
    "Source: System A, Target: System B, Integration: API, Context: Authentication\n",
    "Source: System A, Target: System C, Integration: Webhook, Context: Notifications\n",
    "\n",
    "Question: What are the systems that interact with System A?\n",
    "\n",
    "JSON Response:\n",
    "{\n",
    "  \"query\": \"What are the systems that interact with System A?\",\n",
    "  \"nodes\": [\n",
    "    {\"id\": \"System A\"},\n",
    "    {\"id\": \"System B\"},\n",
    "    {\"id\": \"System C\"}\n",
    "  ],\n",
    "  \"edges\": [\n",
    "    {\"source\": \"System A\", \"target\": \"System B\", \"integration\": \"API\", \"context\": \"Authentication\"},\n",
    "    {\"source\": \"System A\", \"target\": \"System C\", \"integration\": \"Webhook\", \"context\": \"Notifications\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Example 2:\n",
    "Context:\n",
    "Source: Database X, Target: App Y, Integration: REST, Context: Data Transfer\n",
    "Source: Database X, Target: App Z, Integration: GraphQL, Context: Analytics\n",
    "\n",
    "Question: What are the systems that interact with Database X?\n",
    "\n",
    "JSON Response:\n",
    "{\n",
    "  \"query\": \"What are the systems that interact with Database X?\",\n",
    "  \"nodes\": [\n",
    "    {\"id\": \"Database X\"},\n",
    "    {\"id\": \"App Y\"},\n",
    "    {\"id\": \"App Z\"}\n",
    "  ],\n",
    "  \"edges\": [\n",
    "    {\"source\": \"Database X\", \"target\": \"App Y\", \"integration\": \"REST\", \"context\": \"Data Transfer\"},\n",
    "    {\"source\": \"Database X\", \"target\": \"App Z\", \"integration\": \"GraphQL\", \"context\": \"Analytics\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "        # Combine examples with actual query\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that generates JSON responses.\"},\n",
    "            {\"role\": \"user\", \"content\": few_shot_examples},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "Now, based on the following context and question, generate ONLY JSON:\n",
    "\n",
    "Context:\n",
    "{formatted_context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "JSON Response:\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Generate the response using `generate_response`\n",
    "        response_content = generate_response(messages, model=\"gpt-4o-mini\", max_tokens=500, temperature=0.0)\n",
    "        print(\"Raw OpenAI Response:\", response_content)\n",
    "\n",
    "        # Parse the JSON portion of the response\n",
    "        start_index = response_content.find('{')\n",
    "        end_index = response_content.rfind('}')\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            response_json = response_content[start_index:end_index + 1]\n",
    "            return response_json\n",
    "        else:\n",
    "            print(\"No valid JSON found in response.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating JSON response with OpenAI: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Example query for the vector database\n",
    "    example_query = \"What are the systems that interact with Finance System?\"\n",
    "\n",
    "    # Simulated vector DB client (replace with actual client)\n",
    "    def retrieve_context_from_vector_db(vector_db_client, query):\n",
    "        \"\"\"\n",
    "        Simulated retrieval from vector database.\n",
    "\n",
    "        Args:\n",
    "            vector_db_client: Placeholder for vector DB client.\n",
    "            query (str): User query.\n",
    "\n",
    "        Returns:\n",
    "            list: List of relevant context items (mocked).\n",
    "        \"\"\"\n",
    "        return [\n",
    "            {\"source\": \"Finance System\", \"target\": \"Inventory System\", \"integration\": \"ETL\", \"context\": \"Finance\"},\n",
    "            {\"source\": \"Finance System\", \"target\": \"CRM System\", \"integration\": \"REST-API\", \"context\": \"Marketing\"},\n",
    "            {\"source\": \"HR System\", \"target\": \"Finance System\", \"integration\": \"CDC-Stream\", \"context\": \"Employee Data\"},\n",
    "        ]\n",
    "\n",
    "    # Retrieve relevant context from the vector DB\n",
    "    retrieved_context = retrieve_context_from_vector_db(None, example_query)\n",
    "    print(\"Retrieved Context:\", retrieved_context)\n",
    "\n",
    "    # Generate JSON response if context is retrieved\n",
    "    if retrieved_context:\n",
    "        print(\"Testing JSON Generation with Few-Shot Prompt...\")\n",
    "        json_response = generate_json_with_openai_few_shot(retrieved_context, example_query)\n",
    "\n",
    "        # Print the generated JSON response\n",
    "        if json_response:\n",
    "            print(\"Generated JSON Response:\", json_response)\n",
    "        else:\n",
    "            print(\"Failed to generate JSON response.\")\n",
    "    else:\n",
    "        print(\"No context retrieved from Vector DB.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
